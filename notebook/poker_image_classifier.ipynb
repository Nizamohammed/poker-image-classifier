{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4532039,"sourceType":"datasetVersion","datasetId":2579480}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üÉè Poker Card Image Classifier with PyTorch & EfficientNet\n\nIn this notebook, I build a deep learning model to classify images of poker playing cards using a convolutional neural network (CNN).  \nInstead of designing the CNN from scratch, I use **EfficientNet-B0** as a pretrained backbone (via the `timm` library) to leverage transfer learning for better accuracy and faster convergence.\n\n**Key points:**\n\n‚úÖ Custom PyTorch `Dataset` wrapping poker card images organized in folders  \n‚úÖ Transfer learning with `efficientnet_b0` as the feature extractor  \n‚úÖ Custom classifier head on top of EfficientNet  \n‚úÖ Training, validation, and testing loops with loss visualization  \n‚úÖ Evaluation on a separate test set to report final accuracy\n\nThis project was built and run in a Kaggle notebook, using the poker card image dataset stored in:\n- `/kaggle/input/cards-image-datasetclassification/train/`\n- `/kaggle/input/cards-image-datasetclassification/valid/`\n- `/kaggle/input/cards-image-datasetclassification/test/`\n\n**Goal:**  \n> Automatically recognize and classify 53 different poker playing cards from images, exploring CNN architectures and transfer learning as part of my deep learning practice.\n\n---\n\n*Built with: PyTorch, torchvision, timm, numpy, matplotlib & tqdm.*\n\n---","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nimport timm\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport sys\nfrom tqdm.notebook import tqdm\n\nprint('System Version:', sys.version)\nprint('PyTorch version', torch.__version__)\nprint('Torchvision version', torchvision.__version__)\nprint('Numpy version', np.__version__)\nprint('Pandas version', pd.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üóÇ Custom dataset\n\nWe wrap our poker card images in a custom PyTorch `Dataset` using `ImageFolder`, so data is ready for loading.","metadata":{}},{"cell_type":"code","source":"class PokerCardDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data = ImageFolder(data_dir, transform = transform)\n        \n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        return self.data[idx]\n    @property\n    def classes(self):\n        return self.data.classes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üéØ Mapping class indices\n\nGet the mapping from numeric labels to poker card names.","metadata":{}},{"cell_type":"code","source":"# Get a dictionary associating target values with folder names\ndata_dir = '/kaggle/input/cards-image-datasetclassification/train'\ntarget_to_class = {v: k for k, v in ImageFolder(data_dir).class_to_idx.items()}\nprint(target_to_class)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üß† Model: EfficientNet + classifier\n\nWe use `efficientnet_b0` pretrained on ImageNet as feature extractor, and add a linear classifier for 53 poker card classes.","metadata":{}},{"cell_type":"code","source":"class CardClassifer(nn.Module):\n    def __init__(self, num_classes = 53):\n        super(CardClassifer, self).__init__()\n\n        self.base_model = timm.create_model('efficientnet_b0', pretrained = True)\n        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n    \n        enet_out_size = 1280\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(enet_out_size, num_classes)\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        output = self.classifier(x)\n        return output","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîÑ Data transforms & loaders\n\nResize images to 128√ó128 and prepare DataLoader objects for training, validation, and testing.","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((128,128)),\n    transforms.ToTensor(),\n])\n\ntrain_folder = '../input/cards-image-datasetclassification/train/'\nvalid_folder = '../input/cards-image-datasetclassification/valid/'\ntest_folder = '../input/cards-image-datasetclassification/test/'\n\ntrain_dataset = PokerCardDataset(train_folder, transform = transform)\nval_dataset = PokerCardDataset(valid_folder, transform = transform)\ntest_dataset = PokerCardDataset(test_folder, transform = transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False)\ntest_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚öôÔ∏è Training config\n\nSet device (CPU or GPU), define loss function, optimizer, and number of epochs.","metadata":{}},{"cell_type":"code","source":"num_epochs = 8\ntrain_losses, val_losses = [],[]\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = CardClassifer(num_classes = 53)\nmodel.to(device)\n\nloss_func = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)\n\nfor epoch in range(num_epochs):\n\n    model.train()\n    running_loss = 0.0\n    for images, labels in tqdm(train_loader, desc = 'Training loop'):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        output = model(images)\n        loss = loss_func(output, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * labels.size(0)\n\n    train_loss = running_loss / len(train_loader.dataset)\n    train_losses.append(train_loss)\n\n    model.eval()\n    running_loss= 0.0\n    with torch.no_grad():\n        for images, label in tqdm(val_loader, desc = 'Validaton loop'):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = loss_func(output, labels)\n            running_loss += loss.item()*labels.size(0)\n\n    val_loss = running_loss/ len(val_loader.dataset)\n    val_losses.append(val_loss)\n    print(f\"Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss}. Validation Loss: {val_loss}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìà Plotting losses\n\nVisualize how training and validation loss change over epochs.","metadata":{}},{"cell_type":"code","source":"plt.plot(train_losses, label = 'Training Loss')\nplt.plot(val_losses, label = 'Validation Loss')\nplt.legend()\nplt.title(\"Loss over epochs\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚úÖ Evaluate on test set\n\nMeasure final accuracy on unseen test data.","metadata":{}},{"cell_type":"code","source":"correct = 0\ntotal = 0\n\nmodel.eval()\n\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader, desc = 'Testing Loop'):\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = correct/total\nprint(f\"Validation Accuracy: {accuracy:.4f}\")\n\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}